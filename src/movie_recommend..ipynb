{
  "metadata": {
    "name": "movie_recommend",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.sql import SQLContext\nfrom pyspark import SparkConf\n\nconf \u003d SparkConf()\nconf.setMaster(\u0027spark://192.168.56.101:7077\u0027)\nconf.setAppName(\u0027recommend\u0027)\n\nsc \u003d SparkContext.getOrCreate(conf\u003dconf)\n#sc \u003d SparkContext(conf\u003dconf)\nsc.setLogLevel(\"WARN\")\n\nspark \u003d SparkSession(sc)\n\ndata \u003d spark.read.format(\"csv\").option(\"header\", \"true\").option(\"encoding\", \"UTF-8\").load(\"hdfs://hadoop-master:9000/dataset/dataset1/ratings.csv\")\ndata.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sql\nCREATE TABLE ratings (\n    userId int,\n    movieId int,\n    rating double,\n    ts int\n)\nUSING CSV\nOPTIONS (path \"hdfs://hadoop-master:9000/dataset/dataset1/ratings.csv\", header\u003d\"true\")"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndata \u003d spark.table(\"ratings\")\ndata.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Count null value\nfrom pyspark.sql.functions import col,sum\ndata.select(*(sum(col(c).isNull().cast(\"int\")).alias(c) for c in data.columns)).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Count Null value\nfrom pyspark.sql.functions import lit, col\n\nrows \u003d data.count()\nsummary \u003d data.describe().filter(col(\"summary\") \u003d\u003d \"count\")\nsummary.select(*((lit(rows)-col(c)).alias(c) for c in data.columns)).show()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprint(\u0027No. of row: %d\u0027 % data.count())\ndata.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# count, mean, std, min \u0026 max\ndata.describe().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Split dataset to train and test\ntrain_data, test_data \u003d data.randomSplit([0.8, 0.2])"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.ml.recommendation import ALS\nfrom pyspark.ml.evaluation import RegressionEvaluator"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Build the recommendation model using ALS on the training data\nals \u003d ALS(maxIter\u003d10, regParam\u003d0.1, rank\u003d8, nonnegative\u003dTrue, coldStartStrategy\u003d\"drop\",\\\n          userCol\u003d\u0027userId\u0027, itemCol\u003d\u0027movieId\u0027, ratingCol\u003d\u0027rating\u0027)\nmodel \u003d als.fit(train_data)"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprint(\u0027Factorized user matrix with rank \u003d %d\u0027 % model.rank)\nmodel.userFactors.show(5)\n\nprint(\u0027-\u0027*50)\n\nprint(\u0027Factorized item matrix with rank \u003d %d\u0027 % model.rank)\nmodel.itemFactors.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nprint(\u0027Recommended top users (e.g. 1 top user) for all items with the corresponding predicted ratings:\u0027)\nmodel.recommendForAllItems(1).show(5)\n\nprint(\u0027-\u0027*50)\n\nprint(\u0027Recommended top items (e.g. 1 top item) for all users with the corresponding predicted ratings:\u0027)\nmodel.recommendForAllUsers(1).show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nmodel.save(\u0027hdfs://hadoop-master:9000/model\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n#Let see how the model perform\npredictions \u003d model.transform(test_data)\npredictions.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\npredictions.printSchema()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# check the root mean squared error\nevaluator \u003d RegressionEvaluator(metricName\u003d\u0027rmse\u0027, predictionCol\u003d\u0027prediction\u0027, labelCol\u003d\u0027rating\u0027)\nrmse \u003d evaluator.evaluate(predictions)\nprint(\u0027Root mean squared error of the test_data: %.4f\u0027 % rmse)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# see historical rating of the user\nuser_history \u003d train_data.filter(train_data[\u0027userId\u0027]\u003d\u003d11)\nuser_history.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# a list of movies we are thinking to offer\nuser_suggest \u003d test_data.filter(train_data[\u0027userId\u0027]\u003d\u003d11).select([\u0027movieId\u0027, \u0027userId\u0027])\nuser_suggest.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# offer movies with a high predicted rating\nuser_offer \u003d model.transform(user_suggest)\nuser_offer.orderBy(\u0027prediction\u0027, ascending\u003dFalse).show()"
    }
  ]
}